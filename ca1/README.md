In this assignment, our goal is to get familiar with some concepts of Information Theory.

In first part we use our basic knowledge to estimate Enthropy for Stationary Markov Sources.

In second part we divide main chain into smaller groups and generate super-symbols, and calculate average Huffman code length.

In thrid part we use simulation method for Enthropy estimation for memory-less sources.

Finally we can observed the main difference between Markov sources and memory-less sources


![2](https://user-images.githubusercontent.com/79438681/182093771-af5c2870-65f9-4b68-9a5f-5bb90222dfe8.png)
